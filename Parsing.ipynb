{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels as sms\n",
    "import collections\n",
    "import csv\n",
    "import scipy as sp\n",
    "from scipy import interpolate\n",
    "\n",
    "# Variables\n",
    "\n",
    "filenames = [\n",
    "    \"genes_CSP_I7_C1\",\n",
    "    \"genes_CSP_RTS_CONTROL\",\n",
    "    \"genes_iRBC_I7_C1\",\n",
    "    \"genes_iRBC_RTS_CONTROL\",\n",
    "    \"genes_malaria_CSP_CONTROL\",\n",
    "    \"genes_malaria_CSP_RTS\",\n",
    "    \"genes_malaria_iRBC_CONTROL\",\n",
    "    \"genes_malaria_iRBC_RTS\",\n",
    "    \"genes_protected_CSP_C1\",\n",
    "    \"genes_protected_CSP_I7\",\n",
    "    \"genes_protected_iRBC_C1\",\n",
    "    \"genes_protected_iRBC_I7\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain a mapping file from probeset ids to gene symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = pd.read_csv(\"data/HuGene-2_1-st-v1.na36.hg19.probeset.csv\", skiprows = 22)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "probesets   = np.array(D[\"probeset_id\"]) \n",
    "clusts      = np.array(D[\"transcript_cluster_id\"])\n",
    "assigns     = np.array(D[\"gene_assignment\"])\n",
    "rna_assigns = np.array(D[\"mrna_assignment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_transcripts = []\n",
    "for p, c, ass, rna in zip(probes, clusts, assigns, rna_assigns):\n",
    "    for x in ass.split(\" /// \"):\n",
    "        if x == \"---\":\n",
    "            if rna == \"---\": continue\n",
    "            for y in rna.split(\" /// \"):\n",
    "                missing_transcripts += [y.split(\" // \")[0]]\n",
    "missing_transcripts = set(missing_transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a biomaRt script to map these files\n",
    "\n",
    "library(biomaRt)\n",
    "\n",
    "\n",
    "chdir(\"~/Desktop/\")\n",
    "ensembl = useMart(\"ENSEMBL_MART_ENSEMBL\",dataset=\"hsapiens_gene_ensembl\", host = \"www.ensembl.org\")\n",
    "listFilters(ensembl)\n",
    "listAttributes(ensembl)\n",
    "\n",
    "\n",
    "values = read.table(\"~/Desktop/missing_transcripts.tsv\", header = F)$V1\n",
    "\n",
    "ensmap <- getBM(attributes=c(\"ensembl_transcript_id\", \"hgnc_symbol\"), filters = \"ensembl_transcript_id\", values = values, mart= ensembl)\n",
    "\n",
    "emblmap <- getBM(attributes=c(\"embl\", \"hgnc_symbol\"), filter = \"embl\", values = values, mart = ensembl)\n",
    "\n",
    "write.table(ensmap, file = \"~/Desktop/ensemblmap.tsv\", sep = \"\\t\", col.names = T, row.names = F, quote = F)\n",
    "write.table(emblmap, file = \"~/Desktop/emblmap.tsv\", sep = \"\\t\", col.names = T, row.names = F, quote = F)\n",
    "\n",
    "with open(\"data/missing_transcripts.tsv\", \"w\") as f:\n",
    "    for x in sorted(missing_transcripts):\n",
    "        f.write(\"%s\\n\" % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read these files\n",
    "\n",
    "ensmap = pd.read_csv(\"data/ensemblmap.tsv\", delimiter = \"\\t\")\n",
    "emblmap = pd.read_csv(\"data/emblmap.tsv\", delimiter = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrna2gene = collections.defaultdict(set)\n",
    "for r in zip(np.array(ensmap[\"ensembl_transcript_id\"]), np.array(ensmap[\"hgnc_symbol\"])):\n",
    "    if type(r[1]) is not str: continue\n",
    "    mrna2gene[r[0]].update([r[1]])\n",
    "for r in zip(np.array(emblmap[\"embl\"]), np.array(emblmap[\"hgnc_symbol\"])):\n",
    "    if type(r[1]) is not str: continue\n",
    "    mrna2gene[r[0]].update([r[1]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe2gene = collections.defaultdict(set)\n",
    "missing_transcripts = []\n",
    "with open(\"data/probeset2genesymbol.tsv\", \"w\") as f:\n",
    "    for p, c, ass, rna in zip(probesets, clusts, assigns, rna_assigns):\n",
    "        for x in ass.split(\" /// \"):\n",
    "            if x == \"---\":\n",
    "                if rna == \"---\": continue\n",
    "                for y in rna.split(\" /// \"):\n",
    "                    t = y.split(\" // \")[0]\n",
    "                    if t in mrna2gene:\n",
    "                        gs = list(mrna2gene[t])\n",
    "                        for g in gs:\n",
    "                            probe2gene[p].update([g])\n",
    "                            probe2gene[c].update([g])\n",
    "            else:\n",
    "                g = x.split(\" // \")[1]\n",
    "                probe2gene[p].update([g])\n",
    "                probe2gene[c].update([g])\n",
    "    for k,v in probe2gene.iteritems():\n",
    "        for x in v:\n",
    "            f.write(\"%s\\t%s\\n\" % (k, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probeset files and calculate FDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def qvalue(pv, m=None, verbose=False, lowmem=False, pi0=None):\n",
    "    \"\"\"\n",
    "    Estimates q-values from p-values\n",
    "    Args\n",
    "    =====\n",
    "    m: number of tests. If not specified m = pv.size\n",
    "    verbose: print verbose messages? (default False)\n",
    "    lowmem: use memory-efficient in-place algorithm\n",
    "    pi0: if None, it's estimated as suggested in Storey and Tibshirani, 2003.\n",
    "         For most GWAS this is not necessary, since pi0 is extremely likely to be\n",
    "         1\n",
    "    \"\"\"\n",
    "    assert(pv.min() >= 0 and pv.max() <= 1), \"p-values should be between 0 and 1\"\n",
    "\n",
    "    original_shape = pv.shape\n",
    "    pv = pv.ravel()  # flattens the array in place, more efficient than flatten()\n",
    "\n",
    "    if m is None:\n",
    "        m = float(len(pv))\n",
    "    else:\n",
    "        # the user has supplied an m\n",
    "        m *= 1.0\n",
    "\n",
    "    # if the number of hypotheses is small, just set pi0 to 1\n",
    "    if len(pv) < 100 and pi0 is None:\n",
    "        pi0 = 1.0\n",
    "    elif pi0 is not None:\n",
    "        pi0 = pi0\n",
    "    else:\n",
    "        # evaluate pi0 for different lambdas\n",
    "        pi0 = []\n",
    "        lam = sp.arange(0, 0.90, 0.01)\n",
    "        counts = sp.array([(pv > i).sum() for i in sp.arange(0, 0.9, 0.01)])\n",
    "        for l in range(len(lam)):\n",
    "            pi0.append(counts[l]/(m*(1-lam[l])))\n",
    "\n",
    "        pi0 = sp.array(pi0)\n",
    "\n",
    "        # fit natural cubic spline\n",
    "        tck = interpolate.splrep(lam, pi0, k=3)\n",
    "        pi0 = interpolate.splev(lam[-1], tck)\n",
    "        if verbose:\n",
    "            print(\"qvalues pi0=%.3f, estimated proportion of null features \" % pi0)\n",
    "\n",
    "        if pi0 > 1:\n",
    "            if verbose:\n",
    "                print(\"got pi0 > 1 (%.3f) while estimating qvalues, setting it to 1\" % pi0)\n",
    "            pi0 = 1.0\n",
    "\n",
    "    assert(pi0 >= 0 and pi0 <= 1), \"pi0 is not between 0 and 1: %f\" % pi0\n",
    "\n",
    "    if lowmem:\n",
    "        # low memory version, only uses 1 pv and 1 qv matrices\n",
    "        qv = sp.zeros((len(pv),))\n",
    "        last_pv = pv.argmax()\n",
    "        qv[last_pv] = (pi0*pv[last_pv]*m)/float(m)\n",
    "        pv[last_pv] = -sp.inf\n",
    "        prev_qv = last_pv\n",
    "        for i in xrange(int(len(pv))-2, -1, -1):\n",
    "            cur_max = pv.argmax()\n",
    "            qv_i = (pi0*m*pv[cur_max]/float(i+1))\n",
    "            pv[cur_max] = -sp.inf\n",
    "            qv_i1 = prev_qv\n",
    "            qv[cur_max] = min(qv_i, qv_i1)\n",
    "            prev_qv = qv[cur_max]\n",
    "\n",
    "    else:\n",
    "        p_ordered = sp.argsort(pv)\n",
    "        pv = pv[p_ordered]\n",
    "        qv = pi0 * m/len(pv) * pv\n",
    "        qv[-1] = min(qv[-1], 1.0)\n",
    "\n",
    "        for i in xrange(len(pv)-2, -1, -1):\n",
    "            qv[i] = min(pi0*m*pv[i]/(i+1.0), qv[i+1])\n",
    "\n",
    "        # reorder qvalues\n",
    "        qv_temp = qv.copy()\n",
    "        qv = sp.zeros_like(qv)\n",
    "        qv[p_ordered] = qv_temp\n",
    "\n",
    "    # reshape qvalues\n",
    "    qv = qv.reshape(original_shape)\n",
    "\n",
    "    return qv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filenames:\n",
    "\n",
    "    with open(\"data/diff_expr/\"+ filename + \".txt\", \"r\") as f:\n",
    "        f.next()\n",
    "        R = []\n",
    "        probesets = []\n",
    "        for r in csv.reader(f, delimiter = \" \"):\n",
    "            probesets += [r[0]]\n",
    "            R += [[float(r[1]), float(r[2])]]\n",
    "    R = np.array(R)\n",
    "    \n",
    "    q = qvalue(R[:,1])\n",
    "    \n",
    "    with open(\"data/diff_expr/\" + filename + \".tsv\", \"w\") as f:\n",
    "        \n",
    "        for i,p in enumerate(probesets):\n",
    "            \n",
    "            f.write(\"%s\\t%.5f\\t%.5E\\t%.5E\\n\" % (p, R[i,0], R[i,1], q[i]))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map to genes\n",
    "\n",
    "Use the median to aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39116]\n",
      "[0.58188]\n",
      "[0.28763]\n",
      "[-0.36869]\n",
      "[0.16123]\n",
      "[0.1178]\n"
     ]
    }
   ],
   "source": [
    "stats = {}\n",
    "\n",
    "for filename in filenames:\n",
    "\n",
    "    with open(\"data/diff_expr/\" + filename + \".tsv\", \"r\") as f:\n",
    "        \n",
    "        ps = collections.defaultdict(list)\n",
    "        adjps = collections.defaultdict(list)\n",
    "        \n",
    "        fcs = collections.defaultdict(list)\n",
    "\n",
    "        for r in csv.reader(f, delimiter = \"\\t\"):\n",
    "                \n",
    "            for g in probe2gene[int(r[0])]:\n",
    "\n",
    "                fcs[g]   += [float(r[1])]\n",
    "                ps[g]    += [float(r[2])]\n",
    "                adjps[g] += [float(r[3])]\n",
    "        \n",
    "        fcs = dict((k, np.median(v)) for k,v in fcs.iteritems())\n",
    "        ps = dict((k, np.median(v)) for k,v in ps.iteritems())\n",
    "        adjps = dict((k, np.median(v)) for k,v in adjps.iteritems())\n",
    "        \n",
    "    \n",
    "    with open(\"data/diff_expr/\" + filename + \".rnk\", \"w\") as f:\n",
    "                \n",
    "        for w in sorted(fcs, key=fcs.get, reverse=True):\n",
    "            f.write(\"%s\\t%.5f\\t%.3E\\t%.3E\\n\" % (w, fcs[w], ps[w], adjps[w]))\n",
    "    \n",
    "    # Some stats\n",
    "        \n",
    "    P, AP = 0, 0\n",
    "    \n",
    "    for k,v in ps.iteritems():\n",
    "        if v <= 0.05: P += 1\n",
    "    for k,v in adjps.iteritems():\n",
    "        if v <= 0.25: AP += 1\n",
    "              \n",
    "    stats[filename] = (len(ps), P, AP)\n",
    "    \n",
    "with open(\"data/stats.tsv\", \"w\") as f:\n",
    "    \n",
    "    f.write(\"filename\\tgenes\\tp0.05\\tadjp0.25\\n\")\n",
    "    for k,v in stats.iteritems():\n",
    "        f.write(\"%s\\t%d\\t%d\\t%d\\n\" % (k, v[0], v[1], v[2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
